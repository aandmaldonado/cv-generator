# ==========================================
# CV Generator API - Environment Variables Template
# ==========================================
# Copia este archivo a .env y ajusta los valores según tu configuración

# Ollama Configuration
# URL base de Ollama (default: http://localhost:11434)
# Para uso local: http://localhost:11434
# Para Ollama Cloud: https://ollama.com
OLLAMA_BASE_URL=http://localhost:11434

# Modelo de Ollama a utilizar (default: llama3:8b)
# Opciones comunes: llama3:8b, llama3:70b, mistral, codellama, etc.
# Nota: Asegúrate de haber descargado el modelo con: ollama pull llama3:8b
OLLAMA_MODEL=llama3:8b

# Timeout para requests a Ollama en segundos (default: 60)
# Aumenta este valor si trabajas con modelos grandes o conexiones lentas
OLLAMA_TIMEOUT=60

# API Key de Ollama (Opcional)
# Solo necesario si usas Ollama Cloud (https://ollama.com) o servidor remoto con autenticación
# Para uso local NO es necesario
# Puedes obtener tu API key en: https://ollama.com/settings
# OLLAMA_API_KEY=tu_api_key_aqui

# ==========================================
# Optional: Server Configuration
# ==========================================
# Si necesitas configurar el host y puerto del servidor,
# puedes hacerlo en start_server.sh o directamente con uvicorn
# HOST=0.0.0.0
# PORT=8000

# ==========================================
# Optional: Logging Configuration
# ==========================================
# LOG_LEVEL=INFO
# LOG_FORMAT=json

# ==========================================
# Personal Information
# ==========================================
# Número de teléfono personal (opcional)
# Este valor sobrescribe el valor en portfolio.yaml
# Si no se proporciona, se usará el valor del YAML (o None si está vacío)
PHONE_NUMBER=+XX XXX XXX XXX
